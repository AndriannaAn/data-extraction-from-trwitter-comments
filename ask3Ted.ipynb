{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Andrianna Anastasopoulou\n",
    "#1115201300009\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "test_res = pd.read_csv(path+\"/impermium_verification_labels.csv\")\n",
    "\n",
    "test = pd.read_csv(path+\"/impermium_verification_set.csv\")\n",
    "\n",
    "train =  pd.read_csv(path+\"/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=test.astype({'Comment': str})\n",
    "test['Comment']=test['Comment'].apply(lambda col: col.lower())  #convert letters to small\n",
    "test['Comment'] = test['Comment'].replace(r'\\\\n',' ', regex=True)\n",
    "test['Comment'] = test['Comment'].map(lambda x: x.replace(r'\"',''))\n",
    "test['Comment'] = test['Comment'].map(lambda x: x.replace(r'\\xa0',' '))\n",
    "test['Comment'] = test['Comment'].map(lambda x: x.replace(r'\\r',' '))\n",
    "test['Comment'] = test['Comment'].map(lambda x: x.replace(r'_',' '))\n",
    "test['Comment'] = [BeautifulSoup(text).get_text() for text in test['Comment'] ] #removes html\n",
    "test['Comment'] = test['Comment'].map(lambda x: re.sub(r'http\\S+', ' ', x)) #removes links\n",
    "test['Comment'] = test['Comment'].map(lambda x: re.sub(r'@\\S+', ' ', x))\n",
    "test['Comment'] = test['Comment'].map(lambda x: re.sub(r'\\\\u\\S+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.astype({'Comment': str})\n",
    "train['Comment']=train['Comment'].apply(lambda col: col.lower())\n",
    "train['Comment'] = train['Comment'].replace(r'\\\\n',' ', regex=True)\n",
    "train['Comment'] = train['Comment'].map(lambda x: x.replace(r'\"',''))\n",
    "train['Comment'] = train['Comment'].map(lambda x: x.replace(r'\\xa0',' '))\n",
    "train['Comment'] = train['Comment'].map(lambda x: x.replace(r'\\r',' '))\n",
    "train['Comment'] = train['Comment'].map(lambda x: x.replace(r'_',' '))\n",
    "train['Comment'] = train['Comment'].map(lambda x: re.sub(r'http\\S+', ' ', x))\n",
    "train['Comment'] = [BeautifulSoup(text).get_text() for text in train['Comment'] ]\n",
    "train['Comment'] = train['Comment'].map(lambda x: re.sub(r'@\\S+', ' ', x))\n",
    "train['Comment'] = train['Comment'].map(lambda x: re.sub(r'\\\\u\\S+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=train.copy()\n",
    "dftest=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train['Comment'])\n",
    "test_counts = count_vect.transform(test['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6116331096196868\n",
      "F1: 0.6337552742616033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = ComplementNB()\n",
    "clf.fit(train_counts,train['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainA=train.copy()\n",
    "dftestA=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLemmTrain=train.copy()\n",
    "dfLemmTest=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer:\n",
    "     def __init__(self):\n",
    "         self.wnl = WordNetLemmatizer()\n",
    "     def __call__(self, doc):\n",
    "         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(tokenizer=LemmaTokenizer()) \n",
    "train_counts = count_vect.fit_transform(dfLemmTrain['Comment'])\n",
    "test_counts = count_vect.transform(dfLemmTest['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6196868008948546\n",
      "F1: 0.6284965034965034\n"
     ]
    }
   ],
   "source": [
    "clf = ComplementNB() \n",
    "clf.fit(train_counts,dfLemmTrain['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred.astype(int)))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainStop=train.copy()\n",
    "dftestStop=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords :\n",
    "    dftestStop = dftestStop.replace(to_replace=r'\\b%s\\b'%i, value=\"\",regex=True)\n",
    "for i in stopwords :\n",
    "    dftrainStop = dftrainStop.replace(to_replace=r'\\b%s\\b'%i, value=\"\",regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(tokenizer=LemmaTokenizer()) \n",
    "train_counts = count_vect.fit_transform(dftrainStop['Comment'])\n",
    "test_counts = count_vect.transform(dftestStop['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6635346756152125\n",
      "F1: 0.6217303822937627\n"
     ]
    }
   ],
   "source": [
    "clf = ComplementNB() \n",
    "clf.fit(train_counts,dftrainStop['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred.astype(int)))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBigramTrain=train.copy()\n",
    "dfBigramTest=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(2,2)) \n",
    "train_counts = count_vect.fit_transform(dfBigramTrain['Comment'])\n",
    "test_counts = count_vect.transform(dfBigramTest['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6263982102908278\n",
      "F1: 0.5924841386041971\n"
     ]
    }
   ],
   "source": [
    "clf = ComplementNB() \n",
    "clf.fit(train_counts,dfBigramTrain['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred.astype(int)))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLSTrain=train.copy()\n",
    "dfLSTest=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer() \n",
    "train_counts = count_vect.fit_transform(dfLSTrain['Comment'])\n",
    "test_counts = count_vect.transform(dfLSTest['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.680089485458613\n",
      "F1: 0.6372399797057331\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB() #default laplace smoothing\n",
    "clf.fit(train_counts,dfLSTrain['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred.astype(int)))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization,removed stopwords,use of bigrams and laplace smoothing together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainCombined=train.copy()\n",
    "dfTestCombined=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(tokenizer=LemmaTokenizer(),ngram_range=(1,2),stop_words= 'english') \n",
    "train_counts = count_vect.fit_transform(dfTrainCombined['Comment'])\n",
    "test_counts = count_vect.transform(dfTestCombined['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6331096196868009\n",
      "F1: 0.4429347826086957\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() #default laplace smoothing\n",
    "clf.fit(train_counts,dfTrainCombined['Insult'])\n",
    "pred = clf.predict(test_counts)\n",
    "\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred.astype(int)))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Lemmatizer() runs before the removal of the stop words in  CountVectorizer() which worsens the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "# nltk.download('wordnet')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization made scores worst for the parts of speech \n",
    "\n",
    "# dftrain['Comment'] = dftrain['Comment'].apply(lemmatize_text)  \n",
    "# dftest['Comment'] = dftest['Comment'].apply(lemmatize_text)\n",
    "# dftrain=dftrain.astype({'Comment': str})\n",
    "# dftest=dftest.astype({'Comment': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframes should be tokenized in order to add the parts of speech\n",
    "dftrain['Comment'] = dftrain['Comment'].apply(word_tokenize)\n",
    "dftest['Comment'] = dftest['Comment'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTags(text):\n",
    "    posFractions=[]\n",
    "    text = text.apply(lambda x: nltk.pos_tag(x))\n",
    "    for x in text:\n",
    "        total=0\n",
    "        nouns=adjectives=adverbs=verbs=0\n",
    "        for word in x:\n",
    "            if (word[1] == \"NN\" or word[1] == \"NNP\" or word[1] == \"NNS\"):\n",
    "                nouns+=1\n",
    "            elif (word[1] == \"JJ\" or word[1] == \"JJS\" or word[1] == \"JJR\"):\n",
    "                adjectives+=1\n",
    "            elif (word[1] == \"RB\" or word[1] == \"RBR\" or word[1] == \"RBS\"):\n",
    "                adverbs+=1\n",
    "            elif (word[1] == \"VB\" or word[1] == \"VBD\" or word[1] == \"VBG\" or word[1] == \"VBP\" or word[1] == \"VBZ\"):\n",
    "                verbs+=1\n",
    "            total+=1\n",
    "        if total>0:\n",
    "            nouns=nouns/total\n",
    "            adjectives=adjectives/total\n",
    "            adverbs=adverbs/total\n",
    "            verbs=verbs/total\n",
    "        posFractions.append([nouns,adjectives,adverbs,verbs])\n",
    "    return posFractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain.astype({'Comment': str})\n",
    "dftest=dftest.astype({'Comment': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['Comment'] = dftrain['Comment'].str.replace('\\d+', '') # for digits\n",
    "dftrain['Comment'] = dftrain['Comment'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "dftrain['Comment'] = dftrain['Comment'].str.replace('[^\\w\\s]', '') # for punctuation\n",
    "\n",
    "dftest['Comment'] = dftest['Comment'].str.replace('\\d+', '') # for digits\n",
    "dftest['Comment'] = dftest['Comment'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "dftest['Comment'] = dftest['Comment'].str.replace('[^\\w\\s]', '') # for punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsTrain=countTags(dftrain['Comment'])\n",
    "tagsTest=countTags(dftest['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df=2)\n",
    "tf_idf_train = vectorizer.fit_transform(dftrain['Comment'])\n",
    "tf_idf_test = vectorizer.transform(dftest['Comment'])\n",
    "tf_idf_train=np.append(tf_idf_train.toarray(),tagsTrain,axis=1)\n",
    "tf_idf_test=np.append(tf_idf_test.toarray(),tagsTest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf1 = svm.SVC(gamma = 'scale' , C = 5. , kernel = 'rbf')\n",
    "clf1.fit(tf_idf_train,dftrain['Insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.7029082774049217\n",
      "F1: 0.6891010654076857\n"
     ]
    }
   ],
   "source": [
    "pred = clf1.predict(tf_idf_test)\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.6434004474272931\n",
      "F1: 0.6434004474272931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=50)\n",
    "clf2.fit(tf_idf_train,dftrain['Insult'])\n",
    "pred = clf2.predict(tf_idf_test)\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stem_text(text):    \n",
    "    stm = PorterStemmer()\n",
    "    tokenized = word_tokenize(text)\n",
    "    stem_tokes = []\n",
    "    for toke in tokenized:\n",
    "        stem_tokes.append(stm.stem(toke))\n",
    "    stem_tokes\n",
    "    combined = ''\n",
    "    for stemmed in stem_tokes:\n",
    "        combined += stemmed + ' '\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainA['Comment']=dftrainA['Comment'].apply(stem_text)\n",
    "dftestA['Comment']=dftestA['Comment'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainA['Comment'] = dftrainA['Comment'].apply(lemmatize_text)\n",
    "dftestA['Comment'] = dftestA['Comment'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainA=dftrainA.astype({'Comment': str})\n",
    "dftestA=dftestA.astype({'Comment': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2) # stop_words= 'english', removing stopwords drops the accuracy\n",
    "                            )\n",
    "tf_idf_train = vectorizer.fit_transform(dftrainA['Comment'])\n",
    "tf_idf_test = vectorizer.transform(dftestA['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy: 0.7230425055928411\n",
      "F1: 0.7192430430481215\n"
     ]
    }
   ],
   "source": [
    "clf1 = svm.SVC(gamma = 'scale' , C = 5. , kernel = 'linear',class_weight='balanced')\n",
    "clf1.fit(tf_idf_train,dftrainA['Insult'])\n",
    "\n",
    "pred = clf1.predict(tf_idf_test)\n",
    "print ('Test data accuracy:', accuracy_score(test_res['Insult'], pred))\n",
    "print ('F1:',f1_score(test_res['Insult'], pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines using tf-idf\n",
      "\n",
      "10-fold cross validation:\n",
      "Accuracy 0.8109924906711766\n",
      "F1 0.8324991720786354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Support Vector Machines using tf-idf\\n\")\n",
    "print (\"10-fold cross validation:\")\n",
    "accuracy = cross_val_score(clf1, train_counts, dftrainA['Insult'], cv=10, scoring='accuracy')\n",
    "print ('Accuracy', np.mean(accuracy))\n",
    "\n",
    "f1s = cross_val_score(clf1, tf_idf_train, dftrainA['Insult'], cv=10, scoring='f1_weighted')\n",
    "print ('F1', np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
